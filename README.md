# ğŸ‘ï¸ See4You

O **See4You** Ã© um projeto de *Image Captioning* (Legendagem AutomÃ¡tica de Imagens) desenvolvido com o propÃ³sito central de **assistir pessoas com deficiÃªncia visual**. O sistema processa as imagens do ambiente e descreve o cenÃ¡rio em linguagem natural, promovendo maior autonomia e inclusÃ£o digital.

---

## âš™ï¸ Arquitetura e Performance

Para garantir que o projeto possa ser executado em dispositivos com recursos limitados (como smartphones ou sistemas embarcados de assistÃªncia), a eficiÃªncia computacional foi a prioridade mÃ¡xima.

O modelo final utiliza a seguinte arquitetura:
* **Encoder (VisÃ£o):** **MobileNetV3** â€” Rede convolucional prÃ©-treinada, responsÃ¡vel por extrair a representaÃ§Ã£o vetorial da imagem.
* **Decoder (Linguagem):** **GRU** (Gated Recurrent Unit) â€” Rede recorrente responsÃ¡vel pela geraÃ§Ã£o de texto.

### Por que esta escolha?

Realizamos testes rigorosos comparando diferentes redes recorrentes e redes convolucionais prÃ©-treinadas. A combinaÃ§Ã£o **MobileNetV3 + GRU** obteve mÃ©tricas prÃ³ximas Ã s das outras arquiteturas, porÃ©m com uma reduÃ§Ã£o significativa no tempo de execuÃ§Ã£o

| Comparativo de Arquitetura | Ganho de Velocidade |
| :--- | :--- |
| **vs. MobileNetV3 + LSTM** | âš¡ **2.0x mais rÃ¡pida** |
| **vs. ResNet50 + GRU** | âš¡âš¡ **2.5x mais rÃ¡pida** |

Isso significa menos latÃªncia entre a captura da imagem e a descriÃ§Ã£o auditiva para o usuÃ¡rio, algo crÃ­tico para aplicaÃ§Ãµes de acessibilidade.

---
## ğŸ› ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

O projeto foi estruturado para ser reprodutÃ­vel e simples de configurar. Siga os passos abaixo para preparar o ambiente e treinar o modelo.

### 1. Clonar e Instalar DependÃªncias

Clone este repositÃ³rio e instale as bibliotecas necessÃ¡rias:

```bash
git clone [https://github.com/seu-usuario/see4you.git](https://github.com/seu-usuario/see4you.git)
cd see4you
pip install -r requirements.txt
```
### ğŸ“¥ 2. PreparaÃ§Ã£o dos Dados

Antes de iniciar o treinamento, Ã© necessÃ¡rio configurar o ambiente e baixar os dados necessÃ¡rios. Execute o notebook **`setup.ipynb`** para realizar este processo.

**O que este notebook faz:**
* **Dataset:** Baixa e descompacta o dataset de imagens e legendas.
* **Embeddings:** Realiza o download dos embeddings prÃ©-treinados **FastText**.
* **Estrutura:** Cria automaticamente as pastas `/data` e `/embeddings` no diretÃ³rio raiz do projeto.

### ğŸ“Š 3. Treinamento e AvaliaÃ§Ã£o

Com os dados organizados, execute o notebook **`training.ipynb`** para iniciar o pipeline de Deep Learning.

**O fluxo de execuÃ§Ã£o inclui:**
1.  **PrÃ©-processamento:** Carregamento dos DataLoaders e tokenizaÃ§Ã£o.
2.  **Modelagem:** InstanciaÃ§Ã£o da arquitetura **MobileNetV3 + GRU**.
3.  **Treino:** ExecuÃ§Ã£o das Ã©pocas de treinamento com monitoramento da *Loss*.
4.  **Teste:** AvaliaÃ§Ã£o automÃ¡tica utilizando mÃ©tricas de similaridade no conjunto de teste.
